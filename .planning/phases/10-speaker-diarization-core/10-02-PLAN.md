---
phase: 10-speaker-diarization-core
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - cesar/timestamp_aligner.py
  - tests/test_timestamp_aligner.py
autonomous: true

must_haves:
  truths:
    - "Transcription segments get speaker labels based on time overlap"
    - "Segments split at speaker changes for accurate attribution"
    - "Overlapping speech marked as 'Multiple speakers'"
    - "Single speaker output has no speaker labels (normal transcription)"
    - "Misalignment warnings logged but processing continues"
  artifacts:
    - path: "cesar/timestamp_aligner.py"
      provides: "Timestamp alignment between transcription and diarization"
      exports: ["align_timestamps", "AlignedSegment"]
    - path: "tests/test_timestamp_aligner.py"
      provides: "Unit tests for alignment algorithm"
      min_lines: 80
  key_links:
    - from: "cesar/timestamp_aligner.py"
      to: "cesar/diarization.py"
      via: "uses DiarizationResult"
      pattern: "DiarizationResult|SpeakerSegment"
---

<objective>
Create timestamp alignment module that matches transcription segments to speaker labels using temporal intersection algorithm, with segment splitting at speaker changes.

Purpose: Enable accurate speaker attribution for each part of the transcript
Output: Aligned segments with speaker labels, timestamps, and text ready for formatting
</objective>

<execution_context>
@/home/buckleyrobinson/.claude/get-shit-done/workflows/execute-plan.md
@/home/buckleyrobinson/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-speaker-diarization-core/10-RESEARCH.md
@.planning/phases/10-speaker-diarization-core/10-CONTEXT.md
@cesar/diarization.py (from 10-01)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create timestamp alignment module</name>
  <files>
    cesar/timestamp_aligner.py
  </files>
  <action>
    Create cesar/timestamp_aligner.py with timestamp alignment algorithm:

    ```python
    """
    Timestamp alignment between transcription and speaker diarization.

    Aligns Whisper transcription segments to pyannote speaker segments using
    temporal intersection. Handles segment splitting at speaker changes and
    overlapping speech detection.
    """
    import logging
    from dataclasses import dataclass
    from typing import Optional

    from cesar.diarization import DiarizationResult, SpeakerSegment

    logger = logging.getLogger(__name__)

    # Warning threshold: segments with <30% overlap get logged
    ALIGNMENT_WARNING_THRESHOLD = 0.30


    @dataclass
    class TranscriptionSegment:
        """Input segment from Whisper transcription."""
        start: float
        end: float
        text: str


    @dataclass
    class AlignedSegment:
        """Output segment with speaker label."""
        start: float
        end: float
        speaker: str  # "SPEAKER_00", "SPEAKER_01", "Multiple speakers", or "UNKNOWN"
        text: str


    def format_timestamp(seconds: float) -> str:
        """Format seconds as MM:SS.d (decisecond precision).

        Args:
            seconds: Time in seconds

        Returns:
            Formatted string like "01:23.4"
        """
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes:02d}:{secs:04.1f}"


    def _calculate_intersection(seg_start: float, seg_end: float,
                                 spk_start: float, spk_end: float) -> float:
        """Calculate intersection length between two time ranges."""
        intersection_start = max(seg_start, spk_start)
        intersection_end = min(seg_end, spk_end)

        if intersection_start < intersection_end:
            return intersection_end - intersection_start
        return 0.0


    def _find_speakers_in_range(start: float, end: float,
                                 diarization: DiarizationResult) -> list[tuple[str, float, float]]:
        """Find all speakers active during a time range.

        Returns:
            List of (speaker, overlap_start, overlap_end) tuples
        """
        speakers = []
        for seg in diarization.segments:
            intersection = _calculate_intersection(start, end, seg.start, seg.end)
            if intersection > 0:
                overlap_start = max(start, seg.start)
                overlap_end = min(end, seg.end)
                speakers.append((seg.speaker, overlap_start, overlap_end))
        return speakers


    def _detect_overlapping_speech(speakers: list[tuple[str, float, float]]) -> bool:
        """Detect if multiple speakers overlap significantly.

        Two speakers are considered overlapping if their active regions
        within the segment overlap by more than 0.5 seconds.
        """
        if len(speakers) <= 1:
            return False

        # Check pairwise overlap
        for i, (_, start1, end1) in enumerate(speakers):
            for j, (_, start2, end2) in enumerate(speakers[i+1:], i+1):
                overlap = _calculate_intersection(start1, end1, start2, end2)
                if overlap > 0.5:  # 500ms threshold
                    return True
        return False


    def align_timestamps(
        transcription_segments: list[TranscriptionSegment],
        diarization: DiarizationResult,
    ) -> list[AlignedSegment]:
        """Align transcription segments to speaker labels.

        Uses temporal intersection to assign speakers. If a transcription segment
        spans multiple speakers, it is split at speaker change boundaries.

        Args:
            transcription_segments: Segments from Whisper transcription
            diarization: Diarization result with speaker segments

        Returns:
            List of AlignedSegment with speaker labels

        Note:
            - Segments with <30% overlap get a warning logged
            - Overlapping speech (multiple speakers at same time) is marked
            - Single speaker in entire audio means all segments get that speaker
        """
        aligned = []

        # Handle single speaker case - no splitting needed
        if diarization.speaker_count == 1:
            single_speaker = diarization.segments[0].speaker if diarization.segments else "UNKNOWN"
            for seg in transcription_segments:
                aligned.append(AlignedSegment(
                    start=seg.start,
                    end=seg.end,
                    speaker=single_speaker,
                    text=seg.text
                ))
            return aligned

        # Multiple speakers - need to split at boundaries
        for seg in transcription_segments:
            speakers_in_range = _find_speakers_in_range(seg.start, seg.end, diarization)

            if not speakers_in_range:
                # No speaker found for this segment
                logger.warning(
                    f"No speaker found for segment [{format_timestamp(seg.start)} - "
                    f"{format_timestamp(seg.end)}]: '{seg.text[:50]}...'"
                )
                aligned.append(AlignedSegment(
                    start=seg.start,
                    end=seg.end,
                    speaker="UNKNOWN",
                    text=seg.text
                ))
                continue

            if len(speakers_in_range) == 1:
                # Single speaker covers this segment
                speaker, _, _ = speakers_in_range[0]
                segment_duration = seg.end - seg.start
                _, overlap_start, overlap_end = speakers_in_range[0]
                overlap_duration = overlap_end - overlap_start
                overlap_ratio = overlap_duration / segment_duration if segment_duration > 0 else 0

                if overlap_ratio < ALIGNMENT_WARNING_THRESHOLD:
                    logger.warning(
                        f"Low alignment confidence ({overlap_ratio:.0%}) for segment "
                        f"[{format_timestamp(seg.start)} - {format_timestamp(seg.end)}]"
                    )

                aligned.append(AlignedSegment(
                    start=seg.start,
                    end=seg.end,
                    speaker=speaker,
                    text=seg.text
                ))
            else:
                # Multiple speakers in segment - check for overlap or split
                if _detect_overlapping_speech(speakers_in_range):
                    # True overlap - mark as multiple speakers
                    aligned.append(AlignedSegment(
                        start=seg.start,
                        end=seg.end,
                        speaker="Multiple speakers",
                        text=seg.text
                    ))
                else:
                    # Sequential speakers - split segment at boundaries
                    # Sort by overlap start time
                    speakers_in_range.sort(key=lambda x: x[1])

                    # For text splitting, we distribute proportionally by time
                    words = seg.text.split()
                    total_duration = seg.end - seg.start
                    word_idx = 0

                    for i, (speaker, overlap_start, overlap_end) in enumerate(speakers_in_range):
                        # Calculate proportion of words for this speaker
                        speaker_duration = overlap_end - overlap_start
                        proportion = speaker_duration / total_duration if total_duration > 0 else 0

                        # Assign words proportionally
                        if i == len(speakers_in_range) - 1:
                            # Last speaker gets remaining words
                            speaker_words = words[word_idx:]
                        else:
                            word_count = max(1, int(len(words) * proportion))
                            speaker_words = words[word_idx:word_idx + word_count]
                            word_idx += word_count

                        if speaker_words:
                            aligned.append(AlignedSegment(
                                start=overlap_start,
                                end=overlap_end,
                                speaker=speaker,
                                text=" ".join(speaker_words)
                            ))

        return aligned


    def should_include_speaker_labels(diarization: DiarizationResult) -> bool:
        """Determine if speaker labels should be included in output.

        Returns False for single-speaker audio (output looks like normal transcription).

        Args:
            diarization: Diarization result

        Returns:
            True if speaker labels should be shown, False for single speaker
        """
        return diarization.speaker_count > 1
    ```

    Key implementation details per CONTEXT.md decisions:
    - Decisecond precision (00:05.2) in format_timestamp()
    - Split segments at speaker changes (not just majority vote)
    - "Multiple speakers" for overlapping speech (>500ms overlap)
    - Warning logged for <30% alignment confidence (misalignment threshold)
    - Single speaker handling: should_include_speaker_labels() returns False
  </action>
  <verify>
    Run: `python -c "from cesar.timestamp_aligner import align_timestamps, AlignedSegment; print('ok')"`
    Expected: prints "ok"
  </verify>
  <done>
    - cesar/timestamp_aligner.py exists
    - Exports: align_timestamps, AlignedSegment, TranscriptionSegment, format_timestamp, should_include_speaker_labels
    - Temporal intersection algorithm implemented
    - Segment splitting at speaker changes implemented
    - Overlapping speech detection returns "Multiple speakers"
    - Warning logged for low alignment confidence
  </done>
</task>

<task type="auto">
  <name>Task 2: Add comprehensive tests for timestamp alignment</name>
  <files>
    tests/test_timestamp_aligner.py
  </files>
  <action>
    Create tests/test_timestamp_aligner.py with comprehensive unit tests:

    ```python
    """Unit tests for timestamp alignment module."""
    import unittest
    import logging
    from unittest.mock import patch

    from cesar.timestamp_aligner import (
        align_timestamps,
        AlignedSegment,
        TranscriptionSegment,
        format_timestamp,
        should_include_speaker_labels,
        _calculate_intersection,
        _detect_overlapping_speech,
    )
    from cesar.diarization import DiarizationResult, SpeakerSegment


    class TestFormatTimestamp(unittest.TestCase):
        """Tests for timestamp formatting."""

        def test_format_seconds(self):
            """Test formatting seconds."""
            self.assertEqual(format_timestamp(5.2), "00:05.2")

        def test_format_minutes_seconds(self):
            """Test formatting minutes and seconds."""
            self.assertEqual(format_timestamp(65.7), "01:05.7")

        def test_format_zero(self):
            """Test formatting zero."""
            self.assertEqual(format_timestamp(0.0), "00:00.0")

        def test_format_large(self):
            """Test formatting large values."""
            self.assertEqual(format_timestamp(3661.5), "61:01.5")


    class TestCalculateIntersection(unittest.TestCase):
        """Tests for intersection calculation."""

        def test_full_overlap(self):
            """Test when segment is fully within speaker range."""
            result = _calculate_intersection(5.0, 10.0, 0.0, 20.0)
            self.assertEqual(result, 5.0)

        def test_partial_overlap_start(self):
            """Test partial overlap at start."""
            result = _calculate_intersection(5.0, 10.0, 7.0, 15.0)
            self.assertEqual(result, 3.0)

        def test_partial_overlap_end(self):
            """Test partial overlap at end."""
            result = _calculate_intersection(5.0, 10.0, 0.0, 7.0)
            self.assertEqual(result, 2.0)

        def test_no_overlap(self):
            """Test no overlap."""
            result = _calculate_intersection(5.0, 10.0, 15.0, 20.0)
            self.assertEqual(result, 0.0)


    class TestSingleSpeaker(unittest.TestCase):
        """Tests for single speaker handling."""

        def test_single_speaker_no_split(self):
            """Test that single speaker segments don't get split."""
            transcription = [
                TranscriptionSegment(0.0, 10.0, "Hello world"),
                TranscriptionSegment(10.0, 20.0, "How are you"),
            ]
            diarization = DiarizationResult(
                segments=[SpeakerSegment(0.0, 20.0, "SPEAKER_00")],
                speaker_count=1,
                audio_duration=20.0
            )

            result = align_timestamps(transcription, diarization)

            self.assertEqual(len(result), 2)
            self.assertEqual(result[0].speaker, "SPEAKER_00")
            self.assertEqual(result[1].speaker, "SPEAKER_00")
            self.assertEqual(result[0].text, "Hello world")

        def test_should_include_labels_single(self):
            """Test that single speaker returns False for labels."""
            diarization = DiarizationResult(
                segments=[SpeakerSegment(0.0, 10.0, "SPEAKER_00")],
                speaker_count=1,
                audio_duration=10.0
            )
            self.assertFalse(should_include_speaker_labels(diarization))

        def test_should_include_labels_multiple(self):
            """Test that multiple speakers returns True for labels."""
            diarization = DiarizationResult(
                segments=[
                    SpeakerSegment(0.0, 5.0, "SPEAKER_00"),
                    SpeakerSegment(5.0, 10.0, "SPEAKER_01"),
                ],
                speaker_count=2,
                audio_duration=10.0
            )
            self.assertTrue(should_include_speaker_labels(diarization))


    class TestMultipleSpeakers(unittest.TestCase):
        """Tests for multiple speaker alignment."""

        def test_segment_fully_in_speaker_range(self):
            """Test segment fully within one speaker's range."""
            transcription = [
                TranscriptionSegment(2.0, 4.0, "Hello world"),
            ]
            diarization = DiarizationResult(
                segments=[
                    SpeakerSegment(0.0, 5.0, "SPEAKER_00"),
                    SpeakerSegment(5.0, 10.0, "SPEAKER_01"),
                ],
                speaker_count=2,
                audio_duration=10.0
            )

            result = align_timestamps(transcription, diarization)

            self.assertEqual(len(result), 1)
            self.assertEqual(result[0].speaker, "SPEAKER_00")

        def test_segment_split_at_speaker_change(self):
            """Test segment is split when spanning speaker change."""
            transcription = [
                TranscriptionSegment(3.0, 7.0, "Hello world how are you"),
            ]
            diarization = DiarizationResult(
                segments=[
                    SpeakerSegment(0.0, 5.0, "SPEAKER_00"),
                    SpeakerSegment(5.0, 10.0, "SPEAKER_01"),
                ],
                speaker_count=2,
                audio_duration=10.0
            )

            result = align_timestamps(transcription, diarization)

            # Should be split into 2 segments
            self.assertEqual(len(result), 2)
            self.assertEqual(result[0].speaker, "SPEAKER_00")
            self.assertEqual(result[1].speaker, "SPEAKER_01")
            # Text should be distributed
            self.assertTrue(len(result[0].text) > 0)
            self.assertTrue(len(result[1].text) > 0)


    class TestOverlappingSpeech(unittest.TestCase):
        """Tests for overlapping speech handling."""

        def test_detect_overlapping_true(self):
            """Test detection of overlapping speakers."""
            speakers = [
                ("SPEAKER_00", 0.0, 5.0),
                ("SPEAKER_01", 3.0, 8.0),  # Overlaps from 3-5
            ]
            self.assertTrue(_detect_overlapping_speech(speakers))

        def test_detect_overlapping_false(self):
            """Test no overlap detected for sequential speakers."""
            speakers = [
                ("SPEAKER_00", 0.0, 5.0),
                ("SPEAKER_01", 5.5, 10.0),  # Small gap, no overlap
            ]
            self.assertFalse(_detect_overlapping_speech(speakers))

        def test_overlapping_speech_marked(self):
            """Test that overlapping speech is marked as 'Multiple speakers'."""
            transcription = [
                TranscriptionSegment(3.0, 6.0, "Hello world"),
            ]
            diarization = DiarizationResult(
                segments=[
                    SpeakerSegment(0.0, 5.0, "SPEAKER_00"),
                    SpeakerSegment(3.0, 8.0, "SPEAKER_01"),  # Overlaps 3-5
                ],
                speaker_count=2,
                audio_duration=10.0
            )

            result = align_timestamps(transcription, diarization)

            self.assertEqual(len(result), 1)
            self.assertEqual(result[0].speaker, "Multiple speakers")


    class TestMisalignment(unittest.TestCase):
        """Tests for misalignment handling."""

        def test_no_speaker_found_warning(self):
            """Test warning logged when no speaker found."""
            transcription = [
                TranscriptionSegment(15.0, 20.0, "Late segment"),
            ]
            diarization = DiarizationResult(
                segments=[SpeakerSegment(0.0, 10.0, "SPEAKER_00")],
                speaker_count=1,
                audio_duration=10.0
            )

            with self.assertLogs(level=logging.WARNING) as log:
                result = align_timestamps(transcription, diarization)

            self.assertEqual(len(result), 1)
            self.assertEqual(result[0].speaker, "UNKNOWN")
            self.assertTrue(any("No speaker found" in msg for msg in log.output))

        def test_low_confidence_warning(self):
            """Test warning for low alignment confidence."""
            transcription = [
                TranscriptionSegment(0.0, 10.0, "Long segment"),  # 10s duration
            ]
            diarization = DiarizationResult(
                segments=[
                    SpeakerSegment(8.0, 10.0, "SPEAKER_00"),  # Only 2s overlap = 20%
                ],
                speaker_count=2,  # Mark as multi-speaker to trigger check
                audio_duration=10.0
            )

            with self.assertLogs(level=logging.WARNING) as log:
                result = align_timestamps(transcription, diarization)

            self.assertTrue(any("Low alignment confidence" in msg for msg in log.output))


    class TestAlignedSegment(unittest.TestCase):
        """Tests for AlignedSegment dataclass."""

        def test_segment_creation(self):
            """Test creating an aligned segment."""
            segment = AlignedSegment(
                start=1.5,
                end=3.7,
                speaker="SPEAKER_00",
                text="Hello world"
            )

            self.assertEqual(segment.start, 1.5)
            self.assertEqual(segment.end, 3.7)
            self.assertEqual(segment.speaker, "SPEAKER_00")
            self.assertEqual(segment.text, "Hello world")


    if __name__ == "__main__":
        unittest.main()
    ```

    Test coverage:
    - format_timestamp() with various inputs
    - _calculate_intersection() edge cases
    - Single speaker handling (no split, no labels)
    - Multiple speakers (correct assignment, splitting)
    - Overlapping speech detection and marking
    - Misalignment warnings (no speaker, low confidence)
    - AlignedSegment dataclass
  </action>
  <verify>
    Run: `python -m pytest tests/test_timestamp_aligner.py -v`
    Expected: All tests pass
  </verify>
  <done>
    - tests/test_timestamp_aligner.py exists with comprehensive tests
    - Tests cover: single speaker, multiple speakers, splitting, overlap, misalignment
    - All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 3: Run all tests and verify integration</name>
  <files>
    (no new files - verification task)
  </files>
  <action>
    Run comprehensive test suite to verify:
    1. All diarization tests pass: `python -m pytest tests/test_diarization.py -v`
    2. All alignment tests pass: `python -m pytest tests/test_timestamp_aligner.py -v`
    3. All existing tests still pass: `python -m pytest tests/ -v`
    4. Import chain works: `python -c "from cesar.diarization import SpeakerDiarizer; from cesar.timestamp_aligner import align_timestamps; print('all imports ok')"`
  </action>
  <verify>
    Run: `python -m pytest tests/ -v --tb=short`
    Expected: All tests pass, no regressions
  </verify>
  <done>
    - All tests in tests/test_diarization.py pass
    - All tests in tests/test_timestamp_aligner.py pass
    - All existing tests still pass (no regressions)
    - Import chain from diarization to timestamp_aligner works
  </done>
</task>

</tasks>

<verification>
1. Import test: `python -c "from cesar.timestamp_aligner import align_timestamps; print('ok')"`
2. Diarization tests: `python -m pytest tests/test_diarization.py -v`
3. Alignment tests: `python -m pytest tests/test_timestamp_aligner.py -v`
4. Full test suite: `python -m pytest tests/ -v`
</verification>

<success_criteria>
- cesar/timestamp_aligner.py exists with align_timestamps function
- Temporal intersection algorithm correctly assigns speakers
- Segments split at speaker change boundaries
- Overlapping speech marked as "Multiple speakers"
- Single speaker case returns False from should_include_speaker_labels()
- Misalignment warnings logged (but processing continues)
- All unit tests pass
- No regressions in existing tests
</success_criteria>

<output>
After completion, create `.planning/phases/10-speaker-diarization-core/10-02-SUMMARY.md`
</output>
