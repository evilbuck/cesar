---
phase: 14-whisperx-foundation
plan: 02
type: execute
wave: 2
depends_on: ["14-01"]
files_modified:
  - cesar/whisperx_wrapper.py
  - cesar/diarization.py
autonomous: true

must_haves:
  truths:
    - "WhisperXPipeline loads whisperx model successfully"
    - "transcribe_and_diarize() returns aligned segments with speaker labels"
    - "Output format is compatible with existing AlignedSegment from timestamp_aligner.py"
    - "DiarizationError and AuthenticationError exceptions still work"
  artifacts:
    - path: "cesar/whisperx_wrapper.py"
      provides: "WhisperXPipeline class wrapping unified pipeline"
      exports: ["WhisperXPipeline", "WhisperXSegment"]
      min_lines: 100
    - path: "cesar/diarization.py"
      provides: "Preserved exception classes for backward compat"
      contains: "class DiarizationError"
  key_links:
    - from: "cesar/whisperx_wrapper.py"
      to: "whisperx"
      via: "import whisperx"
      pattern: "import whisperx"
    - from: "cesar/whisperx_wrapper.py"
      to: "cesar/diarization.py"
      via: "exception imports"
      pattern: "from cesar\\.diarization import.*Error"
---

<objective>
Create WhisperXPipeline wrapper module for unified transcribe-align-diarize pipeline

Purpose: Encapsulate WhisperX's three-step pipeline (transcribe -> align -> diarize) behind a clean interface that produces output compatible with existing transcript_formatter.py

Output: New cesar/whisperx_wrapper.py module with WhisperXPipeline class
</objective>

<execution_context>
@/home/buckleyrobinson/.claude/get-shit-done/workflows/execute-plan.md
@/home/buckleyrobinson/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-whisperx-foundation/14-RESEARCH.md
@cesar/diarization.py
@cesar/timestamp_aligner.py
@cesar/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create WhisperX wrapper module</name>
  <files>cesar/whisperx_wrapper.py</files>
  <action>
Create new module `cesar/whisperx_wrapper.py` with:

1. **Imports and types:**
```python
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Callable, List

from cesar.diarization import DiarizationError, AuthenticationError
```

2. **WhisperXSegment dataclass** (compatible with AlignedSegment):
```python
@dataclass
class WhisperXSegment:
    """Output segment from WhisperX pipeline.

    Compatible with AlignedSegment from timestamp_aligner.py for
    use with existing MarkdownTranscriptFormatter.
    """
    start: float
    end: float
    speaker: str  # "SPEAKER_00", "SPEAKER_01", etc.
    text: str
```

3. **WhisperXPipeline class:**
```python
class WhisperXPipeline:
    """Wrapper for WhisperX unified pipeline.

    Encapsulates transcription, wav2vec2 alignment, and speaker diarization
    in a single pipeline call. Uses lazy model loading for efficiency.
    """

    DEFAULT_MODEL = "large-v2"
    DEFAULT_BATCH_SIZE = 16

    def __init__(
        self,
        model_name: str = None,
        device: str = "auto",
        compute_type: str = "auto",
        hf_token: Optional[str] = None,
        batch_size: int = None
    ):
        # Store config
        # Resolve device (auto -> cuda if available, else cpu)
        # Resolve compute_type (auto -> float16 for cuda, int8 for cpu)
        # Resolve hf_token using same hierarchy as SpeakerDiarizer
        # Initialize model holders to None (lazy loading)

    def _resolve_token(self, provided_token: Optional[str]) -> Optional[str]:
        # Copy token resolution logic from SpeakerDiarizer
        # 1. provided_token
        # 2. HF_TOKEN env var
        # 3. ~/.cache/huggingface/token file

    def _resolve_device(self, device: str) -> str:
        # "auto" -> check torch.cuda.is_available()
        # Return "cuda" or "cpu"

    def _resolve_compute_type(self, compute_type: str, device: str) -> str:
        # "auto" -> "float16" for cuda, "int8" for cpu

    def _load_whisper_model(self):
        # Lazy load whisperx model
        # whisperx.load_model(self.model_name, self.device, compute_type=self.compute_type)

    def _load_align_model(self, language: str):
        # Lazy load alignment model for detected language
        # whisperx.load_align_model(language_code=language, device=self.device)

    def _load_diarize_model(self):
        # Lazy load diarization pipeline
        # Wrap in try/except to raise AuthenticationError on 401
        # whisperx.DiarizationPipeline(use_auth_token=self.hf_token, device=self.device)

    def transcribe_and_diarize(
        self,
        audio_path: str,
        min_speakers: Optional[int] = None,
        max_speakers: Optional[int] = None,
        progress_callback: Optional[Callable[[str, float], None]] = None
    ) -> tuple[List[WhisperXSegment], int, float]:
        """Run full pipeline: transcribe, align, diarize.

        Args:
            audio_path: Path to audio file
            min_speakers: Minimum expected speakers
            max_speakers: Maximum expected speakers
            progress_callback: Called with (phase_name, percentage)

        Returns:
            Tuple of (segments, speaker_count, audio_duration)

        Raises:
            DiarizationError: If pipeline fails
            AuthenticationError: If HuggingFace auth fails
        """
        # Step 1: Load audio (0%)
        # audio = whisperx.load_audio(audio_path)

        # Step 2: Transcribe (0-40%)
        # if progress_callback: progress_callback("Transcribing...", 0.0)
        # result = self._whisper_model.transcribe(audio, batch_size=self.batch_size)
        # language = result["language"]

        # Step 3: Align (40-60%)
        # if progress_callback: progress_callback("Aligning...", 40.0)
        # result = whisperx.align(result["segments"], ...)

        # Step 4: Diarize (60-90%)
        # if progress_callback: progress_callback("Detecting speakers...", 60.0)
        # diarize_segments = self._diarize_model(audio, min_speakers, max_speakers)

        # Step 5: Assign speakers (90-100%)
        # result = whisperx.assign_word_speakers(diarize_segments, result)

        # Convert to WhisperXSegment format
        return self._convert_to_segments(result)

    def _convert_to_segments(self, result: dict) -> tuple[List[WhisperXSegment], int, float]:
        # Extract segments from result["segments"]
        # Count unique speakers
        # Calculate audio duration from last segment end
        # Return (segments, speaker_count, audio_duration)
```

Key implementation details from RESEARCH.md:
- Use whisperx.load_audio() for audio loading
- Use whisperx.load_model() for transcription model
- Use whisperx.load_align_model() for alignment (language-specific)
- Use whisperx.DiarizationPipeline() for speaker detection
- Use whisperx.assign_word_speakers() for final speaker assignment
- Catch 401/Unauthorized errors and raise AuthenticationError
- Speaker labels come as "SPEAKER_00", "SPEAKER_01" format from WhisperX
  </action>
  <verify>
Run: `python -c "from cesar.whisperx_wrapper import WhisperXPipeline, WhisperXSegment; print('OK')"`
Expected: Prints "OK" without import errors
  </verify>
  <done>
cesar/whisperx_wrapper.py exists with WhisperXPipeline class that imports whisperx and uses DiarizationError/AuthenticationError from diarization.py
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify exception preservation in diarization.py</name>
  <files>cesar/diarization.py</files>
  <action>
Verify diarization.py still exports the exception classes needed by whisperx_wrapper.py:

1. Check DiarizationError class exists (base exception)
2. Check AuthenticationError class exists (inherits from DiarizationError)
3. These classes are used by:
   - whisperx_wrapper.py (new - raises these exceptions)
   - orchestrator.py (catches DiarizationError for fallback)
   - CLI (displays user-friendly error messages)
   - API (returns error responses)

No changes needed to diarization.py for this task - just verify the exceptions exist and are properly exported.

The SpeakerDiarizer class in diarization.py will be deprecated in Phase 15 when orchestrator switches to WhisperXPipeline. For now, both exist side-by-side.
  </action>
  <verify>
Run: `python -c "from cesar.diarization import DiarizationError, AuthenticationError; print('Exceptions OK')"`
Expected: Prints "Exceptions OK"

Run: `python -c "from cesar.whisperx_wrapper import WhisperXPipeline; from cesar.diarization import DiarizationError; print('Cross-module OK')"`
Expected: Prints "Cross-module OK"
  </verify>
  <done>
DiarizationError and AuthenticationError are importable from cesar.diarization and usable by whisperx_wrapper.py
  </done>
</task>

</tasks>

<verification>
1. `python -c "from cesar.whisperx_wrapper import WhisperXPipeline"` succeeds
2. `python -c "from cesar.whisperx_wrapper import WhisperXSegment"` succeeds
3. `grep "class WhisperXPipeline" cesar/whisperx_wrapper.py` finds the class
4. `grep "def transcribe_and_diarize" cesar/whisperx_wrapper.py` finds the main method
5. `grep "from cesar.diarization import" cesar/whisperx_wrapper.py` shows exception imports
</verification>

<success_criteria>
- cesar/whisperx_wrapper.py exists with WhisperXPipeline class
- WhisperXSegment dataclass compatible with AlignedSegment
- transcribe_and_diarize() method implemented with full pipeline
- Exception handling uses DiarizationError and AuthenticationError
- Token resolution uses same hierarchy as existing SpeakerDiarizer
- Lazy model loading implemented (models load on first use)
</success_criteria>

<output>
After completion, create `.planning/phases/14-whisperx-foundation/14-02-SUMMARY.md`
</output>
