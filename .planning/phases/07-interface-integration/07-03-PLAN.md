---
phase: 07-interface-integration
plan: 03
type: execute
wave: 1
depends_on: ["01", "02"]
files_modified:
  - cesar/api/database.py
  - cesar/api/repository.py
  - cesar/api/server.py
  - cesar/api/worker.py
  - tests/test_repository.py
  - tests/test_server.py
  - tests/test_worker.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "API job status endpoint reports download phase with progress percentage"
    - "User can POST /transcribe/url with YouTube URL and job processes successfully with correct status flow"
    - "Job transitions from DOWNLOADING (0%) to DOWNLOADING (100%) to PROCESSING to COMPLETED"
  artifacts:
    - path: "cesar/api/database.py"
      provides: "Schema with download_progress column"
      contains: "download_progress INTEGER"
    - path: "cesar/api/repository.py"
      provides: "CRUD operations that read/write download_progress"
      contains: "download_progress"
    - path: "cesar/api/server.py"
      provides: "YouTube URL detection and DOWNLOADING status initialization"
      contains: "JobStatus.DOWNLOADING"
    - path: "cesar/api/worker.py"
      provides: "YouTube download handling and progress updates"
      contains: "download_progress"
  key_links:
    - from: "cesar/api/database.py"
      to: "cesar/api/repository.py"
      via: "schema includes download_progress column"
      pattern: "download_progress INTEGER"
    - from: "cesar/api/repository.py"
      to: "cesar/api/models.py"
      via: "CRUD operations include download_progress field"
      pattern: "download_progress"
    - from: "cesar/api/server.py"
      to: "Job.status"
      via: "DOWNLOADING initialization for YouTube"
      pattern: "status=JobStatus.DOWNLOADING"
    - from: "cesar/api/worker.py"
      to: "Job.download_progress"
      via: "field update during download"
      pattern: "download_progress"
    - from: "cesar/api/worker.py"
      to: "JobStatus.DOWNLOADING"
      via: "status detection and transition"
      pattern: "JobStatus.DOWNLOADING"
---

<objective>
Close verification gaps for YouTube API job status tracking.

Purpose: The DOWNLOADING status and download_progress field exist in the Job model but are never used. This plan wires them into the server and worker so API users can track YouTube download phase separately from transcription.

Output:
- Server initializes YouTube jobs with DOWNLOADING status and download_progress=0
- Worker detects DOWNLOADING jobs and handles YouTube download phase
- Worker updates download_progress during download (0 -> 100)
- Worker transitions from DOWNLOADING to PROCESSING after download
- Full unit test coverage for new behavior
</objective>

<execution_context>
@/home/buckleyrobinson/.claude/get-shit-done/workflows/execute-plan.md
@/home/buckleyrobinson/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/07-interface-integration/07-VERIFICATION.md
@.planning/phases/07-interface-integration/07-02-SUMMARY.md
@cesar/api/database.py
@cesar/api/repository.py
@cesar/api/models.py
@cesar/api/server.py
@cesar/api/worker.py
@cesar/youtube_handler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add download_progress column to database schema</name>
  <files>cesar/api/database.py</files>
  <action>
Add the download_progress column to the jobs table schema in database.py.

Update the SCHEMA constant to include the new column:
```python
SCHEMA = """
CREATE TABLE IF NOT EXISTS jobs (
    id TEXT PRIMARY KEY,
    status TEXT NOT NULL DEFAULT 'queued',
    audio_path TEXT NOT NULL,
    model_size TEXT NOT NULL DEFAULT 'base',
    created_at TEXT NOT NULL,
    started_at TEXT,
    completed_at TEXT,
    result_text TEXT,
    detected_language TEXT,
    error_message TEXT,
    download_progress INTEGER CHECK(download_progress >= 0 AND download_progress <= 100)
);

CREATE INDEX IF NOT EXISTS idx_jobs_status ON jobs(status);
CREATE INDEX IF NOT EXISTS idx_jobs_created ON jobs(created_at DESC);
"""
```

Note: For existing databases, this column will be added via SQLite's flexible schema handling (new columns with NULL default work). The CHECK constraint ensures values are 0-100 when set.
  </action>
  <verify>
Create a test database and verify schema includes download_progress column:
```bash
python -c "import sqlite3; c = sqlite3.connect(':memory:'); c.executescript(open('cesar/api/database.py').read().split('SCHEMA = \"\"\"')[1].split('\"\"\"')[0]); print([col[1] for col in c.execute('PRAGMA table_info(jobs)').fetchall()])"
```
Output should include 'download_progress'.
  </verify>
  <done>
- SCHEMA includes download_progress column with INTEGER type
- CHECK constraint limits values to 0-100
- Column allows NULL for non-YouTube jobs
  </done>
</task>

<task type="auto">
  <name>Task 2: Update repository CRUD to handle download_progress field</name>
  <files>cesar/api/repository.py, tests/test_repository.py</files>
  <action>
Update JobRepository to read/write the download_progress field in all CRUD operations:

1. Update create() INSERT statement (around line 74-91):
```python
await self._connection.execute(
    """
    INSERT INTO jobs (id, status, audio_path, model_size,
                      created_at, started_at, completed_at,
                      result_text, detected_language, error_message,
                      download_progress)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
    (
        job.id,
        job.status.value,
        job.audio_path,
        job.model_size,
        job.created_at.isoformat(),
        job.started_at.isoformat() if job.started_at else None,
        job.completed_at.isoformat() if job.completed_at else None,
        job.result_text,
        job.detected_language,
        job.error_message,
        job.download_progress,
    ),
)
```

2. Update update() UPDATE statement (around line 124-142):
```python
await self._connection.execute(
    """
    UPDATE jobs SET
        status = ?, started_at = ?, completed_at = ?,
        result_text = ?, detected_language = ?, error_message = ?,
        download_progress = ?
    WHERE id = ?
    """,
    (
        job.status.value,
        job.started_at.isoformat() if job.started_at else None,
        job.completed_at.isoformat() if job.completed_at else None,
        job.result_text,
        job.detected_language,
        job.error_message,
        job.download_progress,
        job.id,
    ),
)
```

3. Update _row_to_job() mapping (around line 172-192) to include download_progress:
```python
def _row_to_job(self, row: tuple) -> Job:
    return Job(
        id=row[0],
        status=JobStatus(row[1]),
        audio_path=row[2],
        model_size=row[3],
        created_at=datetime.fromisoformat(row[4]),
        started_at=datetime.fromisoformat(row[5]) if row[5] else None,
        completed_at=datetime.fromisoformat(row[6]) if row[6] else None,
        result_text=row[7],
        detected_language=row[8],
        error_message=row[9],
        download_progress=row[10],
    )
```

4. Update get_next_queued() to also return DOWNLOADING jobs:
```python
async def get_next_queued(self) -> Optional[Job]:
    """Get the next job that needs processing (QUEUED or DOWNLOADING status).

    Returns jobs in FIFO order by created_at timestamp.
    """
    async with self._connection.execute(
        "SELECT * FROM jobs WHERE status IN ('queued', 'downloading') ORDER BY created_at ASC LIMIT 1"
    ) as cursor:
        row = await cursor.fetchone()
        if row:
            return self._row_to_job(row)
        return None
```

5. Add tests in tests/test_repository.py:
- test_create_job_with_download_progress: Create job with download_progress=50, verify it persists
- test_update_job_download_progress: Create job, update download_progress to 100, verify change persists
- test_get_next_queued_returns_downloading: Create DOWNLOADING job, verify get_next_queued() returns it
- test_get_job_returns_download_progress: Create job with download_progress, retrieve it, verify field is correct
  </action>
  <verify>
Run tests: `python -m pytest tests/test_repository.py -v`
All repository tests pass including new download_progress tests.
  </verify>
  <done>
- create() persists download_progress to database
- update() updates download_progress in database
- _row_to_job() reads download_progress from database row
- get_next_queued() returns DOWNLOADING or QUEUED jobs
- Tests verify all CRUD operations handle download_progress correctly
  </done>
</task>

<task type="auto">
  <name>Task 3: Server YouTube URL detection and DOWNLOADING initialization</name>
  <files>cesar/api/server.py, tests/test_server.py</files>
  <action>
Modify the `/transcribe/url` endpoint in server.py to detect YouTube URLs and initialize jobs differently:

1. Import `is_youtube_url` from `cesar.youtube_handler`
2. Before calling `download_from_url()`, check if `is_youtube_url(request.url)`:
   - If YouTube: Create Job with `status=JobStatus.DOWNLOADING`, `download_progress=0`, store URL in `audio_path` (worker will download)
   - If NOT YouTube: Current behavior (download first, then create Job with QUEUED status)

Key insight: For YouTube URLs, we DON'T download in the endpoint anymore. We store the URL and let the worker handle download + transcription. This allows progress tracking.

Code structure in transcribe_from_url():
```python
if is_youtube_url(request.url):
    # YouTube: Create job with DOWNLOADING status, let worker handle download
    job = Job(
        audio_path=request.url,  # Store URL, not file path
        model_size=request.model,
        status=JobStatus.DOWNLOADING,
        download_progress=0,
    )
    await app.state.repo.create(job)
    return job
else:
    # Regular URL: Download first, then queue
    tmp_path = await download_from_url(request.url)
    job = Job(audio_path=tmp_path, model_size=request.model)
    await app.state.repo.create(job)
    return job
```

Add tests in test_server.py:
- test_transcribe_url_youtube_creates_downloading_status: POST YouTube URL returns job with status=DOWNLOADING, download_progress=0
- test_transcribe_url_regular_creates_queued_status: POST regular URL returns job with status=QUEUED, download_progress=None (existing behavior)
  </action>
  <verify>
Run tests: `python -m pytest tests/test_server.py -v`
All tests pass including new YouTube status tests.
  </verify>
  <done>
- YouTube URL POST returns Job with status=DOWNLOADING and download_progress=0
- Regular URL POST returns Job with status=QUEUED and download_progress=None
- Tests verify both paths
  </done>
</task>

<task type="auto">
  <name>Task 4: Worker YouTube download handling with progress updates</name>
  <files>cesar/api/worker.py, tests/test_worker.py</files>
  <action>
Modify the BackgroundWorker to handle YouTube downloads (jobs with DOWNLOADING status).

Note: Task 2 already updated get_next_queued() to return DOWNLOADING jobs, so worker polling works without changes.

1. Import youtube_handler functions:
```python
from cesar.youtube_handler import (
    is_youtube_url,
    download_youtube_audio,
    YouTubeDownloadError,
    FFmpegNotFoundError,
)
```

2. Modify `_process_job()` to detect DOWNLOADING status and handle YouTube download:
```python
async def _process_job(self, job) -> None:
    self._current_job_id = job.id

    try:
        # Handle YouTube download phase
        if job.status == JobStatus.DOWNLOADING:
            # Update progress to 0 (starting download)
            job.download_progress = 0
            job.started_at = datetime.utcnow()
            await self.repository.update(job)

            # Download YouTube audio (blocking, run in thread pool)
            try:
                audio_path = await asyncio.to_thread(
                    download_youtube_audio,
                    job.audio_path  # Contains the URL
                )
                # Update progress to 100 (download complete)
                job.download_progress = 100
                job.audio_path = str(audio_path)  # Replace URL with file path
                job.status = JobStatus.PROCESSING
                await self.repository.update(job)
            except (YouTubeDownloadError, FFmpegNotFoundError) as e:
                job.status = JobStatus.ERROR
                job.completed_at = datetime.utcnow()
                job.error_message = str(e)
                await self.repository.update(job)
                return
        else:
            # Regular job - update to PROCESSING
            job.status = JobStatus.PROCESSING
            job.started_at = datetime.utcnow()
            await self.repository.update(job)

        # Run transcription (existing logic)
        result = await asyncio.to_thread(...)
        ...
```

Add tests in test_worker.py:
- test_worker_processes_downloading_job: Create job with DOWNLOADING status and YouTube URL, verify worker downloads, updates progress, transitions to PROCESSING, then COMPLETED
- test_worker_downloading_error_sets_error_status: Create DOWNLOADING job, mock download to fail, verify ERROR status with message
- test_worker_queued_job_unchanged: Verify existing QUEUED job behavior still works (regression test)
  </action>
  <verify>
Run tests: `python -m pytest tests/test_worker.py -v`
All tests pass including new YouTube download handling tests.
Run full suite: `python -m pytest tests/ -v` to ensure no regressions.
  </verify>
  <done>
- Worker detects DOWNLOADING status jobs and handles YouTube download
- download_progress updated: 0 at start, 100 after download
- Status transitions: DOWNLOADING -> PROCESSING -> COMPLETED
- YouTube download errors result in ERROR status with message
- All existing worker tests still pass
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Unit tests pass:**
   ```bash
   python -m pytest tests/ -v
   ```
   All tests pass including new gap closure tests.

2. **Database schema verification:**
   - jobs table includes download_progress column
   - Column has CHECK constraint (0-100)
   - Repository CRUD operations handle download_progress field

3. **Integration verification:**
   - POST YouTube URL to /transcribe/url
   - Response has status=DOWNLOADING, download_progress=0
   - GET /jobs/{id} shows status progression: DOWNLOADING -> PROCESSING -> COMPLETED
   - download_progress field shows 0 initially, then 100 after download

4. **Key links verified:**
   - database.py schema includes download_progress column
   - repository.py CRUD operations read/write download_progress
   - server.py sets JobStatus.DOWNLOADING for YouTube URLs
   - worker.py detects DOWNLOADING status and handles download
   - worker.py updates download_progress (0 -> 100)
   - worker.py transitions DOWNLOADING -> PROCESSING -> COMPLETED
</verification>

<success_criteria>
1. Database schema includes download_progress column with CHECK constraint (0-100)
2. Repository CRUD operations persist and retrieve download_progress correctly
3. POST /transcribe/url with YouTube URL returns Job with status=DOWNLOADING and download_progress=0
4. Worker processes DOWNLOADING jobs by downloading YouTube audio first
5. Job.download_progress updates from 0 to 100 during download phase
6. Job status transitions: DOWNLOADING -> PROCESSING -> COMPLETED
7. Download errors set status=ERROR with descriptive message
8. All unit tests pass (existing + new)
9. Regular URL handling unchanged (QUEUED status, no download_progress)
</success_criteria>

<output>
After completion, create `.planning/phases/07-interface-integration/07-03-SUMMARY.md`
</output>
